{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897552b9",
   "metadata": {},
   "source": [
    "MAIN PACKAGES AND LIBRAIRIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b7579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\fabio\\anaconda3\\lib\\site-packages (0.2.9)\n",
      "Requirement already satisfied: packaging in c:\\users\\fabio\\anaconda3\\lib\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: requests in c:\\users\\fabio\\anaconda3\\lib\\site-packages (from kagglehub) (2.24.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fabio\\anaconda3\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\fabio\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\fabio\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\fabio\\anaconda3\\lib\\site-packages (from requests->kagglehub) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fabio\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2020.6.20)\n",
      "Requirement already satisfied: colorama in c:\\users\\fabio\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\fabio\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\fabio\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\fabio\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\fabio\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 484, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"C:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"C:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"C:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: {version!r}\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.13)\n",
      "Path to dataset files: C:\\Users\\fabio\\.cache\\kagglehub\\datasets\\kartik2112\\fraud-detection\\versions\\1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nindex - Unique Identifier for each row\\ntrans_date_trans_time - Transaction DateTime\\ncc_num - Credit Card Number of Customer\\nmerchant - Merchant Name\\ncategory - Category of Merchant\\namt - Amount of Transaction\\nfirst - First Name of Credit Card Holder\\nlast - Last Name of Credit Card Holder\\ngender - Gender of Credit Card Holder\\nstreet - Street Address of Credit Card Holder\\ncity - City of Credit Card Holder\\nstate - State of Credit Card Holder\\nzip - Zip of Credit Card Holder\\nlat - Latitude Location of Credit Card Holder\\nlong - Longitude Location of Credit Card Holder\\ncity_pop - Credit Card Holder's City Population\\njob - Job of Credit Card Holder\\ndob - Date of Birth of Credit Card Holder\\ntrans_num - Transaction Number\\nunix_time - UNIX Time of transaction\\nmerch_lat - Latitude Location of Merchant\\nmerch_long - Longitude Location of Merchant\\nis_fraud - Fraud Flag <--- Target Class\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# To install\n",
    "\n",
    "!pip install kagglehub\n",
    "\n",
    "\n",
    "# To import \n",
    "\n",
    "import kagglehub\n",
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "\n",
    "from datetime                 import datetime\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.preprocessing    import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics          import classification_report, roc_auc_score, confusion_matrix, roc_curve, auc \n",
    "from colorama                 import Fore, Style, Back, init\n",
    "\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"kartik2112/fraud-detection\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "\n",
    "\n",
    "# Legend\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "index - Unique Identifier for each row\n",
    "trans_date_trans_time - Transaction DateTime\n",
    "cc_num - Credit Card Number of Customer\n",
    "merchant - Merchant Name\n",
    "category - Category of Merchant\n",
    "amt - Amount of Transaction\n",
    "first - First Name of Credit Card Holder\n",
    "last - Last Name of Credit Card Holder\n",
    "gender - Gender of Credit Card Holder\n",
    "street - Street Address of Credit Card Holder\n",
    "city - City of Credit Card Holder\n",
    "state - State of Credit Card Holder\n",
    "zip - Zip of Credit Card Holder\n",
    "lat - Latitude Location of Credit Card Holder\n",
    "long - Longitude Location of Credit Card Holder\n",
    "city_pop - Credit Card Holder's City Population\n",
    "job - Job of Credit Card Holder\n",
    "dob - Date of Birth of Credit Card Holder\n",
    "trans_num - Transaction Number\n",
    "unix_time - UNIX Time of transaction\n",
    "merch_lat - Latitude Location of Merchant\n",
    "merch_long - Longitude Location of Merchant\n",
    "is_fraud - Fraud Flag <--- Target Class\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c2b18",
   "metadata": {},
   "source": [
    "STEP 1 - ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a1dc900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[96m\u001b[1m~~~  First values of the train model  ~~~\n",
      "\u001b[95m\u001b[1m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "0           0   2019-01-01 00:00:18  2703186189652095   \n",
       "1           1   2019-01-01 00:00:44      630423337322   \n",
       "2           2   2019-01-01 00:00:51    38859492057661   \n",
       "\n",
       "                          merchant       category     amt      first     last  \\\n",
       "0       fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer    Banks   \n",
       "1  fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie     Gill   \n",
       "2             fraud_Lind-Buckridge  entertainment  220.11     Edward  Sanchez   \n",
       "\n",
       "  gender                        street  ...      lat      long  city_pop  \\\n",
       "0      F                561 Perry Cove  ...  36.0788  -81.1781      3495   \n",
       "1      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105       149   \n",
       "2      M      594 White Dale Suite 530  ...  42.1808 -112.2620      4154   \n",
       "\n",
       "                                 job         dob  \\\n",
       "0          Psychologist, counselling  1988-03-09   \n",
       "1  Special educational needs teacher  1978-06-21   \n",
       "2        Nature conservation officer  1962-01-19   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df_train = pd.read_csv(f\"{path}\\\\fraudTrain.csv\")\n",
    "df_test = pd.read_csv(f\"{path}\\\\fraudTest.csv\")\n",
    "\n",
    "# First analysis\n",
    "\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "text       = \"First values of the train model\"\n",
    "color      = Fore.LIGHTMAGENTA_EX + Style.BRIGHT\n",
    "color_text = Fore.LIGHTCYAN_EX + Style.BRIGHT\n",
    "line       = \"~\" * (len(text) + 10)\n",
    "\n",
    "print(color + line)\n",
    "print(color_text + f\"~~~  {text}  ~~~\")\n",
    "print(color + line + Style.RESET_ALL)\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a28c1",
   "metadata": {},
   "source": [
    "We can observe a lot of irrevelant datas in this dataset. Then, we decide to clean and use only the useful variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61fa5fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[96m\u001b[1m~~~  Trans date time converted in different columns  ~~~\n",
      "\u001b[95m\u001b[1m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>514</td>\n",
       "      <td>8</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78.238288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>241</td>\n",
       "      <td>4</td>\n",
       "      <td>107.23</td>\n",
       "      <td>0</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.752746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>220.11</td>\n",
       "      <td>1</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.790583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num  merchant  category     amt  gender  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095       514         8    4.97       0   \n",
       "1   2019-01-01 00:00:44      630423337322       241         4  107.23       0   \n",
       "2   2019-01-01 00:00:51    38859492057661       390         0  220.11       1   \n",
       "\n",
       "       lat      long  city_pop   unix_time  merch_lat  merch_long  is_fraud  \\\n",
       "0  36.0788  -81.1781      3495  1325376018  36.011293  -82.048315         0   \n",
       "1  48.8878 -118.2105       149  1325376044  49.159047 -118.186462         0   \n",
       "2  42.1808 -112.2620      4154  1325376051  43.150704 -112.154481         0   \n",
       "\n",
       "   hour  day  month   distance  \n",
       "0     0    1      1  78.238288  \n",
       "1     0    1      1   1.752746  \n",
       "2     0    1      1   8.790583  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"trans_date_trans_time\"] = pd.to_datetime(df_train[\"trans_date_trans_time\"], errors=\"coerce\")\n",
    "\n",
    "df_train[\"hour\"]  = df_train[\"trans_date_trans_time\"].dt.hour\n",
    "df_train[\"day\"]   = df_train[\"trans_date_trans_time\"].dt.day\n",
    "df_train[\"month\"] = df_train[\"trans_date_trans_time\"].dt.month\n",
    "\n",
    "drop_columns = [\n",
    "    \"Unnamed: 0\",\n",
    "    \"first\",\n",
    "    \"last\",\n",
    "    \"street\",\n",
    "    \"city\",\n",
    "    \"state\",\n",
    "    \"zip\",\n",
    "    \"dob\",\n",
    "    \"job\",\n",
    "    \"trans_num\"\n",
    "]\n",
    "\n",
    "text       = \"Trans date time converted in different columns\"\n",
    "color      = Fore.LIGHTMAGENTA_EX + Style.BRIGHT\n",
    "color_text = Fore.LIGHTCYAN_EX + Style.BRIGHT\n",
    "line       = \"~\" * (len(text) + 10)\n",
    "\n",
    "print(color + line)\n",
    "print(color_text + f\"~~~  {text}  ~~~\")\n",
    "print(color + line + Style.RESET_ALL)\n",
    "\n",
    "df_train.head(3)\n",
    "\n",
    "df_train = df_train.drop(columns=[c for c in drop_columns if c in df_train.columns])\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35b181ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[96m\u001b[1m~~~  Distance column added in dataset  ~~~\n",
      "\u001b[95m\u001b[1m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>514</td>\n",
       "      <td>8</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78.238288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>241</td>\n",
       "      <td>4</td>\n",
       "      <td>107.23</td>\n",
       "      <td>0</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.752746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>220.11</td>\n",
       "      <td>1</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.790583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>360</td>\n",
       "      <td>2</td>\n",
       "      <td>45.00</td>\n",
       "      <td>1</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.149485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>297</td>\n",
       "      <td>9</td>\n",
       "      <td>41.96</td>\n",
       "      <td>1</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72.218116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-01 00:04:08</td>\n",
       "      <td>4767265376804500</td>\n",
       "      <td>607</td>\n",
       "      <td>2</td>\n",
       "      <td>94.63</td>\n",
       "      <td>0</td>\n",
       "      <td>40.3750</td>\n",
       "      <td>-75.2045</td>\n",
       "      <td>2158</td>\n",
       "      <td>1325376248</td>\n",
       "      <td>40.653382</td>\n",
       "      <td>-76.152667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80.152878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-01 00:04:42</td>\n",
       "      <td>30074693890476</td>\n",
       "      <td>534</td>\n",
       "      <td>3</td>\n",
       "      <td>44.54</td>\n",
       "      <td>0</td>\n",
       "      <td>37.9931</td>\n",
       "      <td>-100.9893</td>\n",
       "      <td>2691</td>\n",
       "      <td>1325376282</td>\n",
       "      <td>37.162705</td>\n",
       "      <td>-100.153370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.662798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-01-01 00:05:08</td>\n",
       "      <td>6011360759745864</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>71.65</td>\n",
       "      <td>1</td>\n",
       "      <td>38.8432</td>\n",
       "      <td>-78.6003</td>\n",
       "      <td>6018</td>\n",
       "      <td>1325376308</td>\n",
       "      <td>38.948089</td>\n",
       "      <td>-78.540296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.192862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-01-01 00:05:18</td>\n",
       "      <td>4922710831011201</td>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0</td>\n",
       "      <td>40.3359</td>\n",
       "      <td>-79.6607</td>\n",
       "      <td>1472</td>\n",
       "      <td>1325376318</td>\n",
       "      <td>40.351813</td>\n",
       "      <td>-79.958146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.208469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-01-01 00:06:01</td>\n",
       "      <td>2720830304681674</td>\n",
       "      <td>563</td>\n",
       "      <td>4</td>\n",
       "      <td>198.39</td>\n",
       "      <td>0</td>\n",
       "      <td>36.5220</td>\n",
       "      <td>-87.3490</td>\n",
       "      <td>151785</td>\n",
       "      <td>1325376361</td>\n",
       "      <td>37.179198</td>\n",
       "      <td>-87.485381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.134652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num  merchant  category     amt  gender  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095       514         8    4.97       0   \n",
       "1   2019-01-01 00:00:44      630423337322       241         4  107.23       0   \n",
       "2   2019-01-01 00:00:51    38859492057661       390         0  220.11       1   \n",
       "3   2019-01-01 00:01:16  3534093764340240       360         2   45.00       1   \n",
       "4   2019-01-01 00:03:06   375534208663984       297         9   41.96       1   \n",
       "5   2019-01-01 00:04:08  4767265376804500       607         2   94.63       0   \n",
       "6   2019-01-01 00:04:42    30074693890476       534         3   44.54       0   \n",
       "7   2019-01-01 00:05:08  6011360759745864       107         2   71.65       1   \n",
       "8   2019-01-01 00:05:18  4922710831011201       250         9    4.27       0   \n",
       "9   2019-01-01 00:06:01  2720830304681674       563         4  198.39       0   \n",
       "\n",
       "       lat      long  city_pop   unix_time  merch_lat  merch_long  is_fraud  \\\n",
       "0  36.0788  -81.1781      3495  1325376018  36.011293  -82.048315         0   \n",
       "1  48.8878 -118.2105       149  1325376044  49.159047 -118.186462         0   \n",
       "2  42.1808 -112.2620      4154  1325376051  43.150704 -112.154481         0   \n",
       "3  46.2306 -112.1138      1939  1325376076  47.034331 -112.561071         0   \n",
       "4  38.4207  -79.4629        99  1325376186  38.674999  -78.632459         0   \n",
       "5  40.3750  -75.2045      2158  1325376248  40.653382  -76.152667         0   \n",
       "6  37.9931 -100.9893      2691  1325376282  37.162705 -100.153370         0   \n",
       "7  38.8432  -78.6003      6018  1325376308  38.948089  -78.540296         0   \n",
       "8  40.3359  -79.6607      1472  1325376318  40.351813  -79.958146         0   \n",
       "9  36.5220  -87.3490    151785  1325376361  37.179198  -87.485381         0   \n",
       "\n",
       "   hour  day  month   distance  \n",
       "0     0    1      1  78.238288  \n",
       "1     0    1      1   1.752746  \n",
       "2     0    1      1   8.790583  \n",
       "3     0    1      1  34.149485  \n",
       "4     0    1      1  72.218116  \n",
       "5     0    1      1  80.152878  \n",
       "6     0    1      1  73.662798  \n",
       "7     0    1      1   5.192862  \n",
       "8     0    1      1  25.208469  \n",
       "9     0    1      1  12.134652  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col  = [\"merchant\", \"category\", \"gender\"]\n",
    "encoders = {}\n",
    "\n",
    "for col in cat_col:\n",
    "    encoders[col] = LabelEncoder()\n",
    "    df_train[col] = encoders[col].fit_transform(df_train[col])\n",
    "\n",
    "def haversine(lat_customer, long_customer, lat_merch, long_merch):\n",
    "    R = 6371\n",
    "    lat_customer, long_customer, lat_merch, long_merch = map(np.radians, [lat_customer, long_customer, lat_merch, long_merch])\n",
    "\n",
    "    dist_lat  = lat_merch  - lat_merch\n",
    "    dist_long = long_merch - long_customer\n",
    "\n",
    "    a = np.sin(dist_lat/2)**2 + np.cos(lat_customer) * np.cos(lat_merch) * np.sin(dist_long/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    \n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "text       = \"Distance column added in dataset\"\n",
    "color      = Fore.LIGHTMAGENTA_EX + Style.BRIGHT\n",
    "color_text = Fore.LIGHTCYAN_EX + Style.BRIGHT\n",
    "line       = \"~\" * (len(text) + 10)\n",
    "\n",
    "print(color + line)\n",
    "print(color_text + f\"~~~  {text}  ~~~\")\n",
    "print(color + line + Style.RESET_ALL)\n",
    "\n",
    "df_train.head(3)\n",
    "\n",
    "df_train[\"distance\"] = haversine(df_train[\"lat\"], df_train[\"long\"], df_train[\"merch_lat\"], df_train[\"merch_long\"])\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c2332d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test columns : \n",
      " \n",
      " Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
      "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
      "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
      "       'merch_lat', 'merch_long', 'is_fraud'],\n",
      "      dtype='object')\n",
      "\n",
      " \n",
      " train columns : \n",
      " \n",
      " Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
      "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
      "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
      "       'merch_lat', 'merch_long', 'is_fraud'],\n",
      "      dtype='object')\n",
      "\n",
      " TRAIN: 1,296,675 rows × 22 columns\n",
      " TEST: 555,719 rows × 22 columns\n",
      "\n",
      " Columns:\n",
      "['trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long', 'is_fraud']\n",
      "\n",
      "================================================================================\n",
      "2. DATA QUALITY\n",
      "================================================================================\n",
      "\n",
      " Missing values - TRAIN: 0, TEST: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a9df92195a9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# Duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mdup_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mdup_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" Duplicates - TRAIN: {dup_train}, TEST: {dup_test}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6662\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6664\u001b[1;33m             ids = get_group_index(\n\u001b[0m\u001b[0;32m   6665\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6666\u001b[0m                 \u001b[1;31m# error: Argument 1 to \"tuple\" has incompatible type \"List[_T]\";\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pandas\\core\\sorting.py\u001b[0m in \u001b[0;36mget_group_index\u001b[1;34m(labels, shape, sort, xnull)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# compute flat ids for the first `nlev` levels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnlev\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(f\"{path}\\\\fraudTrain.csv\")\n",
    "df_test = pd.read_csv(f\"{path}\\\\fraudTest.csv\")\n",
    "\n",
    "# First analysis\n",
    "\n",
    "print(\"test columns : \\n \\n\",df_test.columns)\n",
    "print(\"\\n \\n train columns : \\n \\n\",df_train.columns)\n",
    "\n",
    "# Remove unnecessary index\n",
    "if 'Unnamed: 0' in df_train.columns:\n",
    "    df_train = df_train.drop('Unnamed: 0', axis=1)\n",
    "    df_test = df_test.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "print(f\"\\n TRAIN: {df_train.shape[0]:,} rows × {df_train.shape[1]} columns\")\n",
    "print(f\" TEST: {df_test.shape[0]:,} rows × {df_test.shape[1]} columns\")\n",
    "print(f\"\\n Columns:\\n{list(df_train.columns)}\")\n",
    "\n",
    "df = df_train.copy()\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DATA QUALITY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. DATA QUALITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Missing values\n",
    "missing_train = df_train.isnull().sum().sum()\n",
    "missing_test = df_test.isnull().sum().sum()\n",
    "print(f\"\\n Missing values - TRAIN: {missing_train}, TEST: {missing_test}\")\n",
    "\n",
    "# Duplicates\n",
    "dup_train = df_train.duplicated().sum()\n",
    "dup_test = df_test.duplicated().sum()\n",
    "print(f\" Duplicates - TRAIN: {dup_train}, TEST: {dup_test}\")\n",
    "\n",
    "# Data types\n",
    "print(f\"\\n Data types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# ============================================================================\n",
    "# 3. CLASS IMBALANCE (CRITICAL)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. CLASS IMBALANCE - TARGET 'is_fraud'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "target_col = 'is_fraud'\n",
    "\n",
    "# TRAIN distribution\n",
    "class_dist_train = df_train[target_col].value_counts().sort_index()\n",
    "class_pct_train = (df_train[target_col].value_counts(normalize=True).sort_index() * 100)\n",
    "imbalance_ratio_train = class_dist_train[0] / class_dist_train[1]\n",
    "\n",
    "print(f\"\\n TRAIN:\")\n",
    "print(f\"   Legitimate (0): {class_dist_train[0]:,} ({class_pct_train[0]:.3f}%)\")\n",
    "print(f\"   Fraud (1): {class_dist_train[1]:,} ({class_pct_train[1]:.3f}%)\")\n",
    "print(f\"   Imbalance ratio: {imbalance_ratio_train:.0f}:1\")\n",
    "\n",
    "# TEST distribution\n",
    "class_dist_test = df_test[target_col].value_counts().sort_index()\n",
    "class_pct_test = (df_test[target_col].value_counts(normalize=True).sort_index() * 100)\n",
    "imbalance_ratio_test = class_dist_test[0] / class_dist_test[1]\n",
    "\n",
    "print(f\"\\n TEST:\")\n",
    "print(f\"   Legitimate (0): {class_dist_test[0]:,} ({class_pct_test[0]:.3f}%)\")\n",
    "print(f\"   Fraud (1): {class_dist_test[1]:,} ({class_pct_test[1]:.3f}%)\")\n",
    "print(f\"   Imbalance ratio: {imbalance_ratio_test:.0f}:1\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].bar([0, 1], class_dist_train.values, color=['#2ecc71', '#e74c3c'], \n",
    "           edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_title('TRAIN Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Class', fontsize=11)\n",
    "axes[0].set_ylabel('Count', fontsize=11)\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['Legitimate', 'Fraud'])\n",
    "for i, v in enumerate(class_dist_train.values):\n",
    "    axes[0].text(i, v, f'{v:,}\\n({class_pct_train.values[i]:.3f}%)', \n",
    "               ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "axes[1].bar([0, 1], class_dist_test.values, color=['#3498db', '#e67e22'], \n",
    "           edgecolor='black', linewidth=1.5)\n",
    "axes[1].set_title('TEST Distribution', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Class', fontsize=11)\n",
    "axes[1].set_ylabel('Count', fontsize=11)\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_xticklabels(['Legitimate', 'Fraud'])\n",
    "for i, v in enumerate(class_dist_test.values):\n",
    "    axes[1].text(i, v, f'{v:,}\\n({class_pct_test.values[i]:.3f}%)', \n",
    "               ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_imbalance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 4. KEY FEATURES ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. KEY FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identify feature types\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if target_col in numeric_cols:\n",
    "    numeric_cols.remove(target_col)\n",
    "\n",
    "print(f\"\\n Feature types:\")\n",
    "print(f\"   Numeric: {len(numeric_cols)}\")\n",
    "print(f\"   Categorical: {len(categorical_cols)}\")\n",
    "\n",
    "# Amount analysis\n",
    "print(f\"\\n Amount (amt) statistics:\")\n",
    "print(f\"   Mean: ${df['amt'].mean():.2f}\")\n",
    "print(f\"   Median: ${df['amt'].median():.2f}\")\n",
    "print(f\"   Std: ${df['amt'].std():.2f}\")\n",
    "print(f\"   Range: ${df['amt'].min():.2f} - ${df['amt'].max():.2f}\")\n",
    "\n",
    "print(f\"\\n   By class:\")\n",
    "for cls in [0, 1]:\n",
    "    label = \"Legitimate\" if cls == 0 else \"Fraud\"\n",
    "    mean_amt = df[df[target_col] == cls]['amt'].mean()\n",
    "    print(f\"   {label}: ${mean_amt:.2f}\")\n",
    "\n",
    "# Temporal feature\n",
    "df['trans_datetime'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "print(f\"\\n Time period:\")\n",
    "print(f\"   From: {df['trans_datetime'].min()}\")\n",
    "print(f\"   To: {df['trans_datetime'].max()}\")\n",
    "print(f\"   Duration: {(df['trans_datetime'].max() - df['trans_datetime'].min()).days} days\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 5. BASIC STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n Numeric features summary:\")\n",
    "print(df[numeric_cols].describe().T[['mean', 'std', 'min', 'max']])\n",
    "\n",
    "# ============================================================================\n",
    "# 6. KEY INSIGHTS & NEXT STEPS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. KEY INSIGHTS & NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n KEY FINDINGS:\")\n",
    "print(f\"   1. Severe class imbalance: ~{imbalance_ratio_train:.0f}:1 ratio\")\n",
    "print(f\"   2. {len(numeric_cols)} numeric features, {len(categorical_cols)} categorical\")\n",
    "print(f\"   3. High cardinality in merchant, job → Need encoding strategy\")\n",
    "print(f\"   4. Temporal data available for feature engineering\")\n",
    "print(f\"   5. No missing values (excellent data quality)\")\n",
    "\n",
    "print(\"\\n PREPROCESSING ROADMAP:\")\n",
    "print(\"   1. Drop PII: cc_num, first, last, street, trans_num\")\n",
    "print(\"   2. Temporal features: extract hour, day, day_of_week from trans_date_trans_time\")\n",
    "print(\"   3. Encode categoricals:\")\n",
    "print(\"      • Low cardinality (gender, state): One-Hot or Label Encoding\")\n",
    "print(\"      • High cardinality (category, merchant, job): Target Encoding\")\n",
    "print(\"   4. Scale numeric features: amt, lat, long, city_pop\")\n",
    "print(\"   5. Feature engineering: customer-merchant distance, age from dob\")\n",
    "print(\"   6. Handle imbalance: SMOTE, class_weight, or undersampling\")\n",
    "\n",
    "print(\"\\n MODELING STRATEGY:\")\n",
    "print(\"   • Validation: StratifiedKFold (5-fold)\")\n",
    "print(\"   • Metrics: F1-Score (primary), PR-AUC, ROC-AUC\")\n",
    "print(\"   • Models: Random Forest, Gradient Boosting, XGBoost\")\n",
    "print(\"   • Optimize threshold based on business cost (FP vs FN)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" EXPLORATION COMPLETED - Ready for preprocessing!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b9914",
   "metadata": {},
   "source": [
    "2 - PREPROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5dd937",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['cc_num', 'trans_num', 'first', 'last', 'street'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-897b261cfa0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcol_to_drop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'cc_num'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'trans_num'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'last'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'street'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_to_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_to_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5256\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5257\u001b[0m         \"\"\"\n\u001b[1;32m-> 5258\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   5259\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5260\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4549\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4590\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4591\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\fabio\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6698\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6699\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6700\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6701\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['cc_num', 'trans_num', 'first', 'last', 'street'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop columns we don't need \n",
    "\n",
    "col_to_drop = ['cc_num','trans_num','first','last','street']\n",
    "\n",
    "df_train = df_train.drop(columns=col_to_drop)\n",
    "df_test = df_test.drop(columns=col_to_drop)\n",
    "\n",
    "print(f\" Dropped {len(col_to_drop)} columns\")\n",
    "print(\"test columns : \\n \\n\",df_test.columns)\n",
    "print(\"\\n \\n train columns : \\n \\n\",df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ef799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add / Modify columns so that our model can understand the data \n",
    "\n",
    "\n",
    "# Convert to datetime type \n",
    "df_train['trans_date_trans_time'] = pd.to_datetime(df_train['trans_date_trans_time'])\n",
    "df_test['trans_date_trans_time'] = pd.to_datetime(df_test['trans_date_trans_time'])\n",
    "\n",
    "\n",
    "# Get hours (0 to 23)\n",
    "df_train['hour'] = df_train['trans_date_trans_time'].dt.hour\n",
    "df_test['hour'] = df_test['trans_date_trans_time'].dt.hour\n",
    "\n",
    "# Get day of week (0 = Monday / 6= Sunday)\n",
    "df_train['day_of_week'] = df_train['trans_date_trans_time'].dt.dayofweek\n",
    "df_test['day_of_week'] = df_test['trans_date_trans_time'].dt.dayofweek\n",
    "\n",
    "# Get day of month ( 1 to 31)\n",
    "df_train['day_of_month'] = df_train['trans_date_trans_time'].dt.day\n",
    "df_test['day_of_month'] = df_test['trans_date_trans_time'].dt.day\n",
    "\n",
    "# Get month (1 to 12)\n",
    "df_train['month'] = df_train['trans_date_trans_time'].dt.month\n",
    "df_test['month'] = df_test['trans_date_trans_time'].dt.month\n",
    "\n",
    "# Weekend or not ? \n",
    "df_train['is_weekend'] = (df_train['day_of_week'] >= 5).astype(int)\n",
    "df_test['is_weekend'] = (df_test['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# Function to categrize time of day\n",
    "def get_time_period(hour):\n",
    "    \"\"\" \n",
    "    Categorize hour into time periods\n",
    "    0: Morning (low fraud risk)\n",
    "    1: Afternoon (low fraud risk)\n",
    "    2: Evening (moderate fraud risk)\n",
    "    3: Night (high fraud risk)\n",
    "    \"\"\"\n",
    "    if 5 <= hour < 12:\n",
    "        return 0\n",
    "    elif 12 <= hour < 18:\n",
    "        return 1\n",
    "    elif 18 <= hour < 23:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# Apply \n",
    "df_train['time_period'] = df_train['hour'].apply(get_time_period)\n",
    "df_test['time_period'] = df_train['hour'].apply(get_time_period)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d860d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fraud transaction by hour: \n",
      "hour\n",
      "22    1931\n",
      "23    1904\n",
      "1      658\n",
      "0      635\n",
      "2      625\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop columns we don't need anymore \n",
    "columns_to_drop = ['trans_date_trans_time']\n",
    "\n",
    "df_train = df_train.drop(columns=columns_to_drop)\n",
    "df_test = df_test.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "# Analysis \n",
    "print(\"\\n Fraud transaction by hour: \")\n",
    "fraud_by_hour = df_train[df_train['is_fraud'] == 1].groupby('hour').size()\n",
    "print(fraud_by_hour.sort_values(ascending=False).head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

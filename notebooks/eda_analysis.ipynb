{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a23925a",
   "metadata": {},
   "source": [
    "MAIN PACKAGES AND LIBRAIRIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To install\n",
    "\n",
    "%pip install kagglehub\n",
    "    \n",
    "\n",
    "# To import \n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"kartik2112/fraud-detection\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a49a43",
   "metadata": {},
   "source": [
    "ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df_train = pd.read_csv(f\"{path}\\\\fraudTrain.csv\")\n",
    "df_test = pd.read_csv(f\"{path}\\\\fraudTest.csv\")\n",
    "\n",
    "# First analysis\n",
    "\n",
    "print(\"test columns : \\n \\n\",df_test.columns)\n",
    "print(\"\\n \\n train columns : \\n \\n\",df_train.columns)\n",
    "\n",
    "# Remove unnecessary index\n",
    "if 'Unnamed: 0' in df_train.columns:\n",
    "    df_train = df_train.drop('Unnamed: 0', axis=1)\n",
    "    df_test = df_test.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "print(f\"\\n TRAIN: {df_train.shape[0]:,} rows × {df_train.shape[1]} columns\")\n",
    "print(f\" TEST: {df_test.shape[0]:,} rows × {df_test.shape[1]} columns\")\n",
    "print(f\"\\n Columns:\\n{list(df_train.columns)}\")\n",
    "\n",
    "df = df_train.copy()\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DATA QUALITY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. DATA QUALITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Missing values\n",
    "missing_train = df_train.isnull().sum().sum()\n",
    "missing_test = df_test.isnull().sum().sum()\n",
    "print(f\"\\n Missing values - TRAIN: {missing_train}, TEST: {missing_test}\")\n",
    "\n",
    "# Duplicates\n",
    "dup_train = df_train.duplicated().sum()\n",
    "dup_test = df_test.duplicated().sum()\n",
    "print(f\" Duplicates - TRAIN: {dup_train}, TEST: {dup_test}\")\n",
    "\n",
    "# Data types\n",
    "print(f\"\\n Data types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# ============================================================================\n",
    "# 3. CLASS IMBALANCE (CRITICAL)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. CLASS IMBALANCE - TARGET 'is_fraud'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "target_col = 'is_fraud'\n",
    "\n",
    "# TRAIN distribution\n",
    "class_dist_train = df_train[target_col].value_counts().sort_index()\n",
    "class_pct_train = (df_train[target_col].value_counts(normalize=True).sort_index() * 100)\n",
    "imbalance_ratio_train = class_dist_train[0] / class_dist_train[1]\n",
    "\n",
    "print(f\"\\n TRAIN:\")\n",
    "print(f\"   Legitimate (0): {class_dist_train[0]:,} ({class_pct_train[0]:.3f}%)\")\n",
    "print(f\"   Fraud (1): {class_dist_train[1]:,} ({class_pct_train[1]:.3f}%)\")\n",
    "print(f\"   Imbalance ratio: {imbalance_ratio_train:.0f}:1\")\n",
    "\n",
    "# TEST distribution\n",
    "class_dist_test = df_test[target_col].value_counts().sort_index()\n",
    "class_pct_test = (df_test[target_col].value_counts(normalize=True).sort_index() * 100)\n",
    "imbalance_ratio_test = class_dist_test[0] / class_dist_test[1]\n",
    "\n",
    "print(f\"\\n TEST:\")\n",
    "print(f\"   Legitimate (0): {class_dist_test[0]:,} ({class_pct_test[0]:.3f}%)\")\n",
    "print(f\"   Fraud (1): {class_dist_test[1]:,} ({class_pct_test[1]:.3f}%)\")\n",
    "print(f\"   Imbalance ratio: {imbalance_ratio_test:.0f}:1\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].bar([0, 1], class_dist_train.values, color=['#2ecc71', '#e74c3c'], \n",
    "           edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_title('TRAIN Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Class', fontsize=11)\n",
    "axes[0].set_ylabel('Count', fontsize=11)\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['Legitimate', 'Fraud'])\n",
    "for i, v in enumerate(class_dist_train.values):\n",
    "    axes[0].text(i, v, f'{v:,}\\n({class_pct_train.values[i]:.3f}%)', \n",
    "               ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "axes[1].bar([0, 1], class_dist_test.values, color=['#3498db', '#e67e22'], \n",
    "           edgecolor='black', linewidth=1.5)\n",
    "axes[1].set_title('TEST Distribution', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Class', fontsize=11)\n",
    "axes[1].set_ylabel('Count', fontsize=11)\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_xticklabels(['Legitimate', 'Fraud'])\n",
    "for i, v in enumerate(class_dist_test.values):\n",
    "    axes[1].text(i, v, f'{v:,}\\n({class_pct_test.values[i]:.3f}%)', \n",
    "               ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_imbalance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 4. KEY FEATURES ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. KEY FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identify feature types\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if target_col in numeric_cols:\n",
    "    numeric_cols.remove(target_col)\n",
    "\n",
    "print(f\"\\n Feature types:\")\n",
    "print(f\"   Numeric: {len(numeric_cols)}\")\n",
    "print(f\"   Categorical: {len(categorical_cols)}\")\n",
    "\n",
    "# Amount analysis\n",
    "print(f\"\\n Amount (amt) statistics:\")\n",
    "print(f\"   Mean: ${df['amt'].mean():.2f}\")\n",
    "print(f\"   Median: ${df['amt'].median():.2f}\")\n",
    "print(f\"   Std: ${df['amt'].std():.2f}\")\n",
    "print(f\"   Range: ${df['amt'].min():.2f} - ${df['amt'].max():.2f}\")\n",
    "\n",
    "print(f\"\\n   By class:\")\n",
    "for cls in [0, 1]:\n",
    "    label = \"Legitimate\" if cls == 0 else \"Fraud\"\n",
    "    mean_amt = df[df[target_col] == cls]['amt'].mean()\n",
    "    print(f\"   {label}: ${mean_amt:.2f}\")\n",
    "\n",
    "# Temporal feature\n",
    "df['trans_datetime'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df_test['trans_datetime'] = pd.to_datetime(df_test['trans_date_trans_time'])\n",
    "df_train['trans_datetime'] = pd.to_datetime(df_train['trans_date_trans_time'])\n",
    "\n",
    "print(f\"\\n Time period:\")\n",
    "print(f\"   From: {df['trans_datetime'].min()}\")\n",
    "print(f\"   To: {df['trans_datetime'].max()}\")\n",
    "print(f\"   Duration: {(df['trans_datetime'].max() - df['trans_datetime'].min()).days} days\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 5. BASIC STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n Numeric features summary:\")\n",
    "print(df[numeric_cols].describe().T[['mean', 'std', 'min', 'max']])\n",
    "\n",
    "# ============================================================================\n",
    "# 6. KEY INSIGHTS & NEXT STEPS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. KEY INSIGHTS & NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n KEY FINDINGS:\")\n",
    "print(f\"   1. Severe class imbalance: ~{imbalance_ratio_train:.0f}:1 ratio\")\n",
    "print(f\"   2. {len(numeric_cols)} numeric features, {len(categorical_cols)} categorical\")\n",
    "print(f\"   3. High cardinality in merchant, job → Need encoding strategy\")\n",
    "print(f\"   4. Temporal data available for feature engineering\")\n",
    "print(f\"   5. No missing values (excellent data quality)\")\n",
    "\n",
    "print(\"\\n PREPROCESSING ROADMAP:\")\n",
    "print(\"   1. Drop PII: cc_num, first, last, street, trans_num\")\n",
    "print(\"   2. Temporal features: extract hour, day, day_of_week from trans_date_trans_time\")\n",
    "print(\"   3. Encode categoricals:\")\n",
    "print(\"      • Low cardinality (gender, state): One-Hot or Label Encoding\")\n",
    "print(\"      • High cardinality (category, merchant, job): Target Encoding\")\n",
    "print(\"   4. Scale numeric features: amt, lat, long, city_pop\")\n",
    "print(\"   5. Feature engineering: customer-merchant distance, age from dob\")\n",
    "print(\"   6. Handle imbalance: SMOTE, class_weight, or undersampling\")\n",
    "\n",
    "print(\"\\n MODELING STRATEGY:\")\n",
    "print(\"   • Validation: StratifiedKFold (5-fold)\")\n",
    "print(\"   • Metrics: F1-Score (primary), PR-AUC, ROC-AUC\")\n",
    "print(\"   • Models: Random Forest, Gradient Boosting, XGBoost\")\n",
    "print(\"   • Optimize threshold based on business cost (FP vs FN)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" EXPLORATION COMPLETED - Ready for preprocessing!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "df_train.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
